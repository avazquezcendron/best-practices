
## Performance

The code should not only work, it should also work fast. This is something that clients may not tell the team when providing acceptance criteria, but it definitely does not mean that any number of milliseconds or seconds will be acceptable for the code to run.

The code is often slow for the following reasons:

- Inappropriate data structure or algorithm was chosen to solve the task.
- The code often “modifies” immutable data types, so it leads to a lot of allocations.
- The application fetches small chunks of data from the database instead of fetching    larger chunks one time, so performance suffers because each call to the database is an expensive operation.

A big number of performance issues may never even appear in test or production environments if you ask yourself immediately after completing coding:

> How fast will my code process a larger dataset?

Usually programmers use local databases for development. The local database schema corresponds to a test or production database. However, the amount of data locally may be less due to the fact that in testing or production environment a lot of data is generated by many numbers of active users. This means that your code can always run fast locally, even with very inefficient algorithms.

Imagine that you have implemented logic to check if the user has access to anything:

``` c#
public class UserAccessProvider
{
    private readonly List<User> _users;

    public UserAccessProvider(List<User> users)
    {
        _users = users;
    }

    public bool HasAccess(long userId)
    {
        bool hasAccess = _users.Any(user => user.Id == userId);
        return hasAccess;
    }
}

```

The code on line 12 will work quickly with multiple users, but with millions of users, the performance will be much worse because the List data structure only supports linear searches. It gets worse if the HasAccessmethod is called many times because the complexity will be O(n²).

One solution in this case would be to use a HashSet data structure that performs searches in constant time.

``` c#
public class UserAccessProvider
{
    private readonly HashSet<long> _userIds;

    public UserAccessProvider(List<User> users)
    {
        _userIds = users.Select(u => u.Id).ToHashSet();
    }

    public bool HasAccess(long userId)
    {
        bool hasAccess = _userIds.Contains(userId);
        return hasAccess;
    }
}

```

But don’t waste time implementing an efficient algorithm for a collection that will never have more than 100 items, because no one will ever see the performance difference. Manage your time wisely.

</br>

[Back to Index 👆](./../../README.md#index "Go to Index")